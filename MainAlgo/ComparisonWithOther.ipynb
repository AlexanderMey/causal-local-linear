{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some initializations\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import lingam\n",
    "import pickle\n",
    "import warnings\n",
    "from scipy.stats import binomtest\n",
    "import itertools\n",
    "import loli\n",
    "from heapq import nlargest\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[490. 132.  16.   4.  12.   9.]\n",
      " [ 54. 402. 357.  67.  86. 120.]\n",
      " [ 74. 452. 462.  32.  35.  48.]\n",
      " [  6.   8.   6. 495. 192.  12.]\n",
      " [102. 104. 164.  64. 327. 317.]\n",
      " [ 32.  59.  51. 101. 443. 443.]]\n",
      "[[ True  True False False False False]\n",
      " [False  True  True  True  True  True]\n",
      " [ True  True  True False False False]\n",
      " [False False False  True  True False]\n",
      " [ True  True  True  True  True  True]\n",
      " [False False False  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from scipy.stats import binomtest\n",
    "import numpy as np\n",
    "E=300\n",
    "n=30\n",
    "with open('LorenzResults='+str(E)+'N'+str(n)+'.pkl','rb') as f:\n",
    "    Lorenz30=pickle.load(f)\n",
    "\n",
    "final=np.zeros((6,6))\n",
    "for tar in range(6):\n",
    "    for key in Lorenz30[tar]:\n",
    "        for var in range(6):\n",
    "            if var in key:\n",
    "                final[tar,var]+=Lorenz30[tar][key]\n",
    "\n",
    "print(final)\n",
    "pvals=np.zeros((6,6))\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        test=binomtest(np.int32(final[i,j]),500,0.1,alternative='greater')\n",
    "        pvals[i,j]=test.pvalue\n",
    "print(pvals<0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinomTestResult(k=54, n=500, alternative='greater', statistic=0.108, pvalue=0.29593284067935044)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binomtest(54,500,0.1,alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Via Stack Overflow\n",
    "# https://stackoverflow.com/questions/11130156/suppress-stdout-stderr-print-from-python-functions\n",
    "# Supressing the output of annyoing libraries\n",
    "from contextlib import contextmanager,redirect_stderr,redirect_stdout\n",
    "from os import devnull\n",
    "\n",
    "@contextmanager\n",
    "def suppress_stdout_stderr():\n",
    "    \"\"\"A context manager that redirects stdout and stderr to devnull\"\"\"\n",
    "    with open(devnull, 'w') as fnull:\n",
    "        with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:\n",
    "            yield (err, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yerr(tot,res):\n",
    "    yerrbar=np.zeros((2,len(res)))\n",
    "    for i in range(len(res)):\n",
    "\n",
    "        if res[i]>1:\n",
    "            res[i]=1\n",
    "        if res[i]<0:\n",
    "            res[i]=0\n",
    "        result = binomtest(k=int(res[i]*tot), n=tot, p=res[i])\n",
    "        yerrbar[0,i]=res[i]-result.proportion_ci()[0]\n",
    "        yerrbar[1,i]=result.proportion_ci()[1]-res[i]\n",
    "    return yerrbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size 1 of 4\n",
      "Sample size 2 of 4\n",
      "Sample size 3 of 4\n",
      "Sample size 4 of 4\n"
     ]
    }
   ],
   "source": [
    "### Changing sample size\n",
    "np.random.seed(1)\n",
    "d=6  #Dimensionality\n",
    "supp=(1,2) #support indices\n",
    "s=len(supp)  #Number of support entries\n",
    "sample=[8,16,24,32]\n",
    "fntrunc=np.zeros((len(sample)))\n",
    "fptrunc=np.zeros((len(sample)))\n",
    "fnt=np.zeros((len(sample)))\n",
    "fpt=np.zeros((len(sample)))\n",
    "fnlingtrunc=np.zeros((len(sample)))\n",
    "fplingtrunc=np.zeros((len(sample)))\n",
    "fnlingt=np.zeros((len(sample)))\n",
    "fplingt=np.zeros((len(sample)))\n",
    "runs=300\n",
    "nmax=sample[-1]\n",
    "l=1 # Number of intervals we combine for the statistics\n",
    "B=100 # Bootstrap runs\n",
    "I=30      #Number of Intervals \n",
    "a=[list(itertools.combinations(range(d), k)) for k in range(0,d+1)]\n",
    "subsets = [item for sublist in a for item in sublist]\n",
    "dic={}\n",
    "# We first fix the data for all runs, to eliminate the randomness of this.\n",
    "betas=np.zeros((d))\n",
    "x_uni=np.zeros((runs,I,nmax,d))\n",
    "x_t=np.zeros((runs,I,nmax,d))\n",
    "y_uni=np.zeros((runs,I,nmax))\n",
    "y_t=np.zeros((runs,I,nmax))\n",
    "for r in range(runs):\n",
    "    for i in range(I):\n",
    "        betas[np.array(supp)]=np.random.uniform(low=1,high=5,size=(s))\n",
    "        std=np.random.uniform(low=1,high=5,size=(d))\n",
    "        x_uni[r,i,:,0]=np.random.uniform(low=-6*std[0]**2,high=6*std[0]**2,size=(nmax))\n",
    "        x_uni[r,i,:,1]=x_uni[r,i,:,0]+np.random.uniform(low=-6*std[1]**2,high=6*std[1]**2,size=(nmax))\n",
    "        x_uni[r,i,:,2]=0.3*x_uni[r,i,:,1]+np.random.uniform(low=-6*std[2]**2,high=6*std[2]**2,size=(nmax))\n",
    "        x_uni[r,i,:,3]=0.2*x_uni[r,i,:,2]+np.random.uniform(low=-6*std[3]**2,high=6*std[3]**2,size=(nmax))\n",
    "        e=np.random.uniform(low=-6*2**2,high=6*2**2,size=(nmax))\n",
    "        y_uni[r,i,:]=x_uni[r,i,:,:]@betas+e\n",
    "        x_uni[r,i,:,4]=np.random.uniform(low=-6*std[4]**2,high=6*std[4]**2,size=(nmax))+0.1*x_uni[r,i,:,1]+y_uni[r,i,:]\n",
    "        x_uni[r,i,:,5]=np.random.uniform(low=-6*std[4]**2,high=6*std[4]**2,size=(nmax))+y_uni[r,i,:]\n",
    "        \n",
    "        \n",
    "        x_t[r,i,:,0]=np.random.standard_t(2*(std[0])**(2)/((std[0])**(2)-1),size=(nmax))\n",
    "        x_t[r,i,:,1]=x_t[r,i,:,0]+np.random.standard_t(2*(std[1])**(2)/((std[1])**(2)-1),size=(nmax))\n",
    "        x_t[r,i,:,2]=0.3*x_t[r,i,:,1]+np.random.standard_t(2*(std[2])**(2)/((std[2])**(2)-1),size=(nmax))\n",
    "        x_t[r,i,:,3]=0.2*x_t[r,i,:,2]+np.random.standard_t(2*(std[3])**(2)/((std[3])**(2)-1),size=(nmax))\n",
    "        e=np.random.standard_t(2*(2)**(2)/((2)**(2)-1),size=(nmax))\n",
    "        y_t[r,i,:]=x_t[r,i,:]@betas+e\n",
    "        x_t[r,i,:,4]=np.random.standard_t(2*(std[4])**(2)/((std[4])**(2)-1),size=(nmax))+0.1*x_t[r,i,:,1]+y_t[r,i,:]\n",
    "        x_t[r,i,:,5]=np.random.standard_t(2*(std[5])**(2)/((std[5])**(2)-1),size=(nmax))+y_t[r,i,:]\n",
    "            \n",
    "            \n",
    "for o,n in enumerate(sample):\n",
    "    print('Sample size',o+1,'of',len(sample))\n",
    "    for r in range(runs):\n",
    "        Xt=[]\n",
    "        Yt=[]\n",
    "        Xtrunc=[]\n",
    "        Ytrunc=[]\n",
    "        X_lingtrunc=[]\n",
    "        X_lingt=[]\n",
    "        for i in range(I):\n",
    "            x_lingtrunc=np.zeros((n,d+1))\n",
    "            x_lingt=np.zeros((n,d+1))\n",
    "            \n",
    "            Xtrunc.append(x_uni[r,i,:n,:])\n",
    "            Ytrunc.append(y_uni[r,i,:n])\n",
    "            \n",
    "            x_lingtrunc[:,:d]=copy.copy(x_uni[r,i,:n,:])\n",
    "            x_lingtrunc[:,d]=copy.copy(y_uni[r,i,:n])\n",
    "            \n",
    "            X_lingtrunc.append(x_lingtrunc)\n",
    "\n",
    "\n",
    "            Xt.append(x_t[r,i,:n,:])\n",
    "            Yt.append(y_t[r,i,:n])\n",
    "            x_lingt[:,:d]=copy.copy(x_t[r,i,:n,:])\n",
    "            x_lingt[:,d]=copy.copy(y_t[r,i,:n])\n",
    "            X_lingt.append(x_lingt)\n",
    "            \n",
    "        with suppress_stdout_stderr():\n",
    "            model=lingam.MultiGroupDirectLiNGAM()\n",
    "            model.fit(X_lingt)\n",
    "\n",
    "            \n",
    "        plausibleS=loli.gauss(Xt,Yt,alpha=0.1)\n",
    "        if not not plausibleS:\n",
    "            supphat=set.intersection(*plausibleS)\n",
    "            if len(supphat.difference(set(supp)))>0:\n",
    "                fpt[o]+=1/runs\n",
    "            if len(set(supp).difference(supphat))>0:\n",
    "                fnt[o]+=1/runs\n",
    "                \n",
    "        lingmat=model.adjacency_matrices_[0][6,:]\n",
    "        lingsupp=np.where(lingmat!=0)\n",
    "        supphatling=set(lingsupp[0])\n",
    "        if len(supphatling.difference(set(supp)))>0:\n",
    "            fplingt[o]+=1/runs\n",
    "        if len(set(supp).difference(supphatling))>0:\n",
    "            fnlingt[o]+=1/runs\n",
    "            \n",
    "        with suppress_stdout_stderr():\n",
    "            model=lingam.MultiGroupDirectLiNGAM()\n",
    "            model.fit(X_lingtrunc)\n",
    "\n",
    "            \n",
    "        plausibleS=loli.gauss(Xtrunc,Ytrunc,alpha=0.1)\n",
    "        if not not plausibleS:\n",
    "            supphat=set.intersection(*plausibleS)\n",
    "            if len(supphat.difference(set(supp)))>0:\n",
    "                fptrunc[o]+=1/runs\n",
    "            if len(set(supp).difference(supphat))>0:\n",
    "                fntrunc[o]+=1/runs\n",
    "                \n",
    "        lingmat=model.adjacency_matrices_[0][6,:]\n",
    "        lingsupp=np.where(lingmat!=0)\n",
    "        supphatling=set(lingsupp[0])\n",
    "        if len(supphatling.difference(set(supp)))>0:\n",
    "            fplingtrunc[o]+=1/runs\n",
    "        if len(set(supp).difference(supphatling))>0:\n",
    "            fnlingtrunc[o]+=1/runs\n",
    "            \n",
    "\n",
    "\n",
    "ComparisonLingSample={}\n",
    "ComparisonLingSample['fpt']=fpt\n",
    "ComparisonLingSample['fnt']=fnt\n",
    "ComparisonLingSample['fptrunc']=fptrunc\n",
    "ComparisonLingSample['fntrunc']=fntrunc\n",
    "ComparisonLingSample['fplingt']=fplingt\n",
    "ComparisonLingSample['fnlingt']=fnlingt\n",
    "ComparisonLingSample['fnlingtrunc']=fnlingtrunc\n",
    "ComparisonLingSample['fplingtrunc']=fplingtrunc\n",
    "ComparisonLingSample['sample']=sample\n",
    "\n",
    "with open('ComparisonLingSample.pkl', 'wb') as f:\n",
    "    pickle.dump(ComparisonLingSample, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Changing heterogeneity\n",
    "np.random.seed(1)\n",
    "d=6  #Dimensionality\n",
    "supp=(1,2) #support indices\n",
    "s=len(supp)  #Number of support entries\n",
    "hetero=[0,0.5,1,1.5,2]\n",
    "fntrunc=np.zeros((len(hetero)))\n",
    "fptrunc=np.zeros((len(hetero)))\n",
    "fnt=np.zeros((len(hetero)))\n",
    "fpt=np.zeros((len(hetero)))\n",
    "fnlingtrunc=np.zeros((len(hetero)))\n",
    "fplingtrunc=np.zeros((len(hetero)))\n",
    "fnlingt=np.zeros((len(hetero)))\n",
    "fplingt=np.zeros((len(hetero)))\n",
    "runs=300\n",
    "n=20\n",
    "l=1 # Number of intervals we combine for the statistics\n",
    "B=100 # Bootstrap runs\n",
    "I=30      #Number of Intervals \n",
    "a=[list(itertools.combinations(range(d), k)) for k in range(0,d+1)]\n",
    "subsets = [item for sublist in a for item in sublist]\n",
    "dic={}\n",
    "\n",
    "betas=np.zeros((runs,I,d))\n",
    "\n",
    "for o,h in enumerate(hetero):\n",
    "    print('Heterogeneity',o+1,'of',len(hetero))\n",
    "    for r in range(runs):\n",
    "        Xt=[]\n",
    "        Yt=[]\n",
    "        Xtrunc=[]\n",
    "        Ytrunc=[]\n",
    "        X_lingtrunc=[]\n",
    "        X_lingt=[]\n",
    "        for i in range(I):\n",
    "            betas[r,i,supp]=np.random.uniform(low=1,high=1+h,size=(s))\n",
    "            x=np.zeros((n,d))\n",
    "            x_lingtrunc=np.zeros((n,d+1))\n",
    "            x_lingt=np.zeros((n,d+1))\n",
    "            y=np.zeros((n))\n",
    "            std=np.random.uniform(low=2,high=2+h,size=(d))\n",
    "            x[:,0]=np.random.uniform(low=-6*std[0]**2,high=6*std[0]**2,size=(n))\n",
    "            x[:,1]=x[:,0]+np.random.uniform(low=-6*std[1]**2,high=6*std[1]**2,size=(n))\n",
    "            x[:,2]=0.3*x[:,1]+np.random.uniform(low=-6*std[2]**2,high=6*std[2]**2,size=(n))\n",
    "            x[:,3]=0.2*x[:,2]+np.random.uniform(low=-6*std[3]**2,high=6*std[3]**2,size=(n))\n",
    "            e=np.random.uniform(low=-6*2**2,high=6*2**2,size=(n))\n",
    "            y=x@betas[r,i,:]+e\n",
    "            x[:,4]=np.random.uniform(low=-6*std[4]**2,high=6*std[4]**2,size=(n))+0.1*x[:,1]+y\n",
    "            x[:,5]=np.random.uniform(low=-6*std[4]**2,high=6*std[4]**2,size=(n))+y\n",
    "\n",
    "            Xtrunc.append(x)\n",
    "            Ytrunc.append(y)\n",
    "            x_lingtrunc[:,:d]=copy.copy(x)\n",
    "            x_lingtrunc[:,d]=copy.copy(y)\n",
    "            X_lingtrunc.append(x_lingtrunc)\n",
    "            \n",
    "            x=np.zeros((n,d))\n",
    "            y=np.zeros((n))\n",
    "            std=np.random.uniform(low=2,high=2+h,size=(d))\n",
    "            x[:,0]=np.random.standard_t(2*(std[0])**(2)/((std[0])**(2)-1),size=(n))\n",
    "            x[:,1]=x[:,0]+np.random.standard_t(2*(std[1])**(2)/((std[1])**(2)-1),size=(n))\n",
    "            x[:,2]=0.3*x[:,1]+np.random.standard_t(2*(std[2])**(2)/((std[2])**(2)-1),size=(n))\n",
    "            x[:,3]=0.2*x[:,2]+np.random.standard_t(2*(std[3])**(2)/((std[3])**(2)-1),size=(n))\n",
    "            e=np.random.standard_t(2*(2)**(2)/((2)**(2)-1),size=(n))\n",
    "            y=x@betas[r,i,:]+e\n",
    "            x[:,4]=np.random.standard_t(2*(std[4])**(2)/((std[4])**(2)-1),size=(n))+0.1*x[:,1]+y\n",
    "            x[:,5]=np.random.standard_t(2*(std[5])**(2)/((std[5])**(2)-1),size=(n))+y\n",
    "\n",
    "            Xt.append(x)\n",
    "            Yt.append(y)\n",
    "            x_lingt[:,:d]=copy.copy(x)\n",
    "            x_lingt[:,d]=copy.copy(y)\n",
    "            X_lingt.append(x_lingt)\n",
    "            \n",
    "        with suppress_stdout_stderr():\n",
    "            model=lingam.MultiGroupDirectLiNGAM()\n",
    "            model.fit(X_lingt)\n",
    "\n",
    "            \n",
    "        plausibleS=loli.gauss(Xt,Yt,alpha=0.1)\n",
    "        if not not plausibleS:\n",
    "            supphat=set.intersection(*plausibleS)\n",
    "            if len(supphat.difference(set(supp)))>0:\n",
    "                fpt[o]+=1/runs\n",
    "            if len(set(supp).difference(supphat))>0:\n",
    "                fnt[o]+=1/runs\n",
    "                \n",
    "        lingmat=model.adjacency_matrices_[0][6,:]\n",
    "        lingsupp=np.where(lingmat!=0)\n",
    "        supphatling=set(lingsupp[0])\n",
    "        if len(supphatling.difference(set(supp)))>0:\n",
    "            fplingt[o]+=1/runs\n",
    "        if len(set(supp).difference(supphatling))>0:\n",
    "            fnlingt[o]+=1/runs\n",
    "            \n",
    "        with suppress_stdout_stderr():\n",
    "            model=lingam.MultiGroupDirectLiNGAM()\n",
    "            model.fit(X_lingtrunc)\n",
    "\n",
    "            \n",
    "        plausibleS=loli.gauss(Xtrunc,Ytrunc,alpha=0.1)\n",
    "        if not not plausibleS:\n",
    "            supphat=set.intersection(*plausibleS)\n",
    "            if len(supphat.difference(set(supp)))>0:\n",
    "                fptrunc[o]+=1/runs\n",
    "            if len(set(supp).difference(supphat))>0:\n",
    "                fntrunc[o]+=1/runs\n",
    "                \n",
    "        lingmat=model.adjacency_matrices_[0][6,:]\n",
    "        lingsupp=np.where(lingmat!=0)\n",
    "        supphatling=set(lingsupp[0])\n",
    "        if len(supphatling.difference(set(supp)))>0:\n",
    "            fplingtrunc[o]+=1/runs\n",
    "        if len(set(supp).difference(supphatling))>0:\n",
    "            fnlingtrunc[o]+=1/runs\n",
    "        \n",
    "\n",
    "ComparisonLingHetero={}\n",
    "ComparisonLingHetero['fpt']=fpt\n",
    "ComparisonLingHetero['fnt']=fnt\n",
    "ComparisonLingHetero['fptrunc']=fptrunc\n",
    "ComparisonLingHetero['fntrunc']=fntrunc\n",
    "ComparisonLingHetero['fplingt']=fplingt\n",
    "ComparisonLingHetero['fnlingt']=fnlingt\n",
    "ComparisonLingHetero['fnlingtrunc']=fnlingtrunc\n",
    "ComparisonLingHetero['fplingtrunc']=fplingtrunc\n",
    "ComparisonLingHetero['hetero']=hetero\n",
    "\n",
    "with open('ComparisonLingHetero2.pkl', 'wb') as f:\n",
    "    pickle.dump(ComparisonLingHetero, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environments 1 of 6\n",
      "Environments 2 of 6\n",
      "Environments 3 of 6\n",
      "Environments 4 of 6\n",
      "Environments 5 of 6\n",
      "Environments 6 of 6\n"
     ]
    }
   ],
   "source": [
    "### Changing number of environments\n",
    "np.random.seed(1)\n",
    "d=6  #Dimensionality\n",
    "supp=(1,2) #support indices\n",
    "s=len(supp)  #Number of support entries\n",
    "for n in range[16,24]:\n",
    "    environments=[30,50,80,100,150,200]\n",
    "    # environments=[150,200]\n",
    "    fnt=np.zeros((len(environments)))\n",
    "    fpt=np.zeros((len(environments)))\n",
    "    fnlingt=np.zeros((len(environments)))\n",
    "    fplingt=np.zeros((len(environments)))\n",
    "    runs=300\n",
    "    l=1 # Number of intervals we combine for the statistics\n",
    "    B=100 # Bootstrap runs\n",
    "    Imax=environments[-1]\n",
    "    a=[list(itertools.combinations(range(d), k)) for k in range(0,d+1)]\n",
    "    subsets = [item for sublist in a for item in sublist]\n",
    "    dic={}\n",
    "    # We first fix the data for all runs, to eliminate the randomness of this.\n",
    "    betas=np.zeros((d))\n",
    "    x_uni=np.zeros((runs,Imax,n,d))\n",
    "    x_t=np.zeros((runs,Imax,n,d))\n",
    "    y_uni=np.zeros((runs,Imax,n))\n",
    "    y_t=np.zeros((runs,Imax,n))\n",
    "    for r in range(runs):\n",
    "        for i in range(Imax):\n",
    "            betas[np.array(supp)]=np.random.uniform(low=1,high=5,size=(s))\n",
    "            std=np.random.uniform(low=1,high=5,size=(d))\n",
    "\n",
    "            x_t[r,i,:,0]=np.random.standard_t(2*(std[0])**(2)/((std[0])**(2)-1),size=(n))\n",
    "            x_t[r,i,:,1]=x_t[r,i,:,0]+np.random.standard_t(2*(std[1])**(2)/((std[1])**(2)-1),size=(n))\n",
    "            x_t[r,i,:,2]=0.3*x_t[r,i,:,1]+np.random.standard_t(2*(std[2])**(2)/((std[2])**(2)-1),size=(n))\n",
    "            x_t[r,i,:,3]=0.2*x_t[r,i,:,2]+np.random.standard_t(2*(std[3])**(2)/((std[3])**(2)-1),size=(n))\n",
    "            e=np.random.standard_t(2*(2)**(2)/((2)**(2)-1),size=(n))\n",
    "            y_t[r,i,:]=x_t[r,i,:]@betas+e\n",
    "            x_t[r,i,:,4]=np.random.standard_t(2*(std[4])**(2)/((std[4])**(2)-1),size=(n))+0.1*x_t[r,i,:,1]+y_t[r,i,:]\n",
    "            x_t[r,i,:,5]=np.random.standard_t(2*(std[5])**(2)/((std[5])**(2)-1),size=(n))+y_t[r,i,:]\n",
    "\n",
    "\n",
    "    for o,I in enumerate(environments):\n",
    "        print('Environments',o+1,'of',len(environments))\n",
    "        for r in range(runs):\n",
    "            Xt=[]\n",
    "            Yt=[]\n",
    "            X_lingt=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            for i in range(I):\n",
    "                x_lingt=np.zeros((n,d+1))\n",
    "                x=x_t[r,i,:,:]\n",
    "                y=y_t[r,i,:]\n",
    "                Xt.append(x)\n",
    "                Yt.append(y)\n",
    "                x_lingt[:,:d]=copy.copy(x)\n",
    "                x_lingt[:,d]=copy.copy(y)\n",
    "                X_lingt.append(x_lingt)\n",
    "\n",
    "            with suppress_stdout_stderr():\n",
    "                model=lingam.MultiGroupDirectLiNGAM()\n",
    "                model.fit(X_lingt)\n",
    "\n",
    "\n",
    "            plausibleS=loli.gauss(Xt,Yt,alpha=0.1)\n",
    "            if not not plausibleS:\n",
    "                supphat=set.intersection(*plausibleS)\n",
    "                if len(supphat.difference(set(supp)))>0:\n",
    "                    fpt[o]+=1/runs\n",
    "                if len(set(supp).difference(supphat))>0:\n",
    "                    fnt[o]+=1/runs\n",
    "\n",
    "            lingmat=model.adjacency_matrices_[0][6,:]\n",
    "            lingsupp=np.where(lingmat!=0)\n",
    "            supphatling=set(lingsupp[0])\n",
    "            if len(supphatling.difference(set(supp)))>0:\n",
    "                fplingt[o]+=1/runs\n",
    "            if len(set(supp).difference(supphatling))>0:\n",
    "                fnlingt[o]+=1/runs\n",
    "\n",
    "\n",
    "\n",
    "    ComparisonLingEnvironments={}\n",
    "    ComparisonLingEnvironments['fpt']=fpt\n",
    "    ComparisonLingEnvironments['fnt']=fnt\n",
    "    ComparisonLingEnvironments['fplingt']=fplingt\n",
    "    ComparisonLingEnvironments['fnlingt']=fnlingt\n",
    "    ComparisonLingEnvironments['environments']=environments\n",
    "\n",
    "    with open('ComparisonLingEnvironmentsN='+str(n)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(ComparisonLingEnvironments, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
